---
title: Heat in India
# subtitle: A slightly longer title
format:
  360-analysis-html: default
author: James Goldie
date: last-modified
code-fold: true
---

```{r}
#| label: setup
library(tidyverse)
library(here)
library(ecmwfr)
library(ClimateOperators)
# library(sf)
# library(terra)
library(exactextractr)
```

# Retrieving the ERA5 data

The ECMWF API requires authentication. When rendering this document, ensure a `.Renviron` file is present with an environment variable. The variable name should be the username prefixed with `ecmwfr_cds:`, and the value should be the key:

```
ecmwfr_cds:[user]=[key]
```

We're going to download one year at a time, to `/data/raw/YYYY.nc`. Let's work out which ones are missing.

:::{.callout-warning}
Downloading 50 years of hourly temperature data requires substantial disk space - about 14 GB for India.

It also takes a good while to download from CDS, as there is server-side processing required for each annual file (about 12 hours, by my testing). It may make sense to run this code interactively, but as it only downloads missing files, you should be fine re-running it if there's a failure.
:::

```{r}
#| label: authenticate
cds_keys <-
  here(".Renviron") |>
  readLines() |>
  keep(str_starts, "ecmwfr_cds:")

# check exactly one key
stopifnot(
    "There should be exactly one environment variable of the form `ecmwfr_cds:[user]=[key]`" =
  length(cds_keys) == 1)

# isolate the username
username <-
  cds_keys |>
  str_split("=") |>
  unlist() |>
  pluck(1) |>
  str_remove("ecmwfr_cds:")

# request template (for parameters that don't change)
request_template <- list(
  dataset_short_name = "reanalysis-era5-single-levels",
  product_type = "reanalysis",
  variable = "2m_temperature",
  month = c(
    "01", "02", "03",
    "04", "05", "06",
    "07", "08", "09",
    "10", "11", "12"),
  day = c(
    "01", "02", "03",
    "04", "05", "06",
    "07", "08", "09",
    "10", "11", "12",
    "13", "14", "15",
    "16", "17", "18",
    "19", "20", "21",
    "22", "23", "24",
    "25", "26", "27",
    "28", "29", "30",
    "31"),
  time = c(
    "00:00", "01:00", "02:00",
    "03:00", "04:00", "05:00",
    "06:00", "07:00", "08:00",
    "09:00", "10:00", "11:00",
    "12:00", "13:00", "14:00",
    "15:00", "16:00", "17:00",
    "18:00", "19:00", "20:00",
    "21:00", "22:00", "23:00"),
  area = "35.5/68.17/7.9/97.41",
  format = "netcdf")

# which years do we need to download?
here("data", "raw", "hourly", paste0(1970:year(Sys.Date()), ".nc")) |>
  discard(file.exists) ->
missing_files

# make a separate request for each missing year (if there are any)
if (length(missing_files) > 0) {

  missing_files |>
    map(~ c(
      request_template,
      year = str_remove(basename(.x), ".nc"),
      target = basename(.x))) ->
  cds_request_list

  dir.create(here("data", "raw", "hourly"), recursive = TRUE,
    showWarnings = FALSE)

  # this might take a long, *long* time if there are many years to retrieve!
  wf_request_batch(
    request_list = cds_request_list,
    user         = username,
    path         = here("data", "raw", "hourly"))

}

```

:::{.callout-note}
ERA5 includes "preliminary" data for the most recent few months, and "final" data. Unforunately, [according to ECMWF](https://confluence.ecmwf.int/display/CKB/ERA5%3A+data+documentation) (emphasis mine):

> For netCDF data requests which return just ERA5 or just ERA5T data, **there is no means of differentiating between ERA5 and ERA5T data in the resulting netCDF files.**
> 
> For netCDF data requests which return a mixture of ERA5 and ERA5T data, the origin of the variables (1 or 5) will be identifiable in the resulting netCDF files. See this [link](https://confluence.ecmwf.int/pages/viewpage.action?pageId=173385064) for more details.

Because of this, we need to be careful when no `expver` is present â€” it could be all "final" data or (if we're running this in the first few months of the year) all "preliminary" data.

But since preliminary data is never going to extend a full year ahead of the final data, we should assume that:

- if the data is not for the current year, and it has no `expver`, it's all final
- if the data _is_ for the current year, and it has no `expver`, it's all preliminary

It's probably easier to go back and reconstruct which years include preliminary data at the end and just tack the two together.
:::

## Boundaries

Let's get the boundaries of India and its states using `{rgeoboundaries}`:

```{r}
#| label: get-boundaries
boundaries_india <- gb_adm0("india", type = )
boundaries_states <- gb_adm1("india", type = )
```

# Analysis

The basic process will be that for each year, we:

- Calculate the daily tmax and tmin
- Calculate the number of days/nights available and the number of days/nights >= X Â°C in each region
- Crop to selected areas (either India as a whole or sections of it)

Then, join the annual statistics up into a single file.

## Daily maxima and minima

```{r}
#| label: calc-tmax-tmin
dir.create(here("data", "raw", "daily"), showWarnings = FALSE)

calc_tmax_tmin <- function(path) {
  cdo(
    "-L",
    "-daymax",
    csl("-selname", "t2m"),
    path,
    here("data", "raw", "daily", paste0("tmax-", basename(path))))
  cdo(
    "-L",
    "-daymin",
    csl("-selname", "t2m"),
    path,
    here("data", "raw", "daily", paste0("tmin-", basename(path))))
}

# here("data", "raw", "hourly", "2023.nc") |> map(calc_tmax_tmin)
list.files(
  here("data", "raw", "hourly"),
  pattern = glob2rx("*.nc"),
  full.names = TRUE) |>
  map(calc_tmax_tmin, .progress = TRUE)
```

## Count days exceeding threshold

```{r}
#| label: calc-days-gte-fn
dir.create(here("data", "raw", "days-gte"), showWarning = FALSE)

calc_days_gte <- function(path, thresh) {
  cdo(
    "-L",
    "-b F64",
    "-yearsum",
    csl("-gec", thresh + 273.15),
    csl("-selname", "t2m"),
    path,
    here("data", "raw", "days-gte",
      paste0("gte", thresh, "-", basename(path))))
}

tmax_thresh <- 40
tmin_thresh <- 30
```

Now we'll calculate the number of days each year that exceed the threshold: `{r} tmax_threshold` Â°C for tmax and `{r} tmin_threshold` Â°C for tmin.

```{r}
#| label: calc-days-gte
# tmax >= 40Â°C
list.files(
  here("data", "raw", "daily"),
  pattern = glob2rx("tmax-*.nc"),
  full.names = TRUE) |>
  map(calc_days_gte, thresh = tmax_thresh, .progress = TRUE)

# tmin >= 30Â°C
list.files(
  here("data", "raw", "daily"),
  pattern = glob2rx("tmin-*.nc"),
  full.names = TRUE) |>
  map(calc_days_gte, thresh = tmin_thresh, .progress = TRUE)
```

For some reason, the 2024 file has come in with an additional `exprver` dimension. I think this might be a vertical level, but I'm not sure. But we can't concatenate it with the other grids if it's a different shape ðŸ¤”

<!-- TODO - combine era5 and era5t data! -->

## Concatenating annual count grids

Now combine each "days over" grid into a single time series grid:

```{r}
#| label: combine
dir.create(here("data", "raw", "days-gte-concat"), showWarnings = FALSE)

concat_annual_gte <- function(paths, thresh, var) {
  cdo(
    "-L",
    "mergetime",
    here("data", "raw", "days-gte", "gte30-tmin-*.nc"),
    here("data", "raw", "days-gte-concat",
      "gte30-tmin.nc")
  )
}

tibble(
  path = list.files(
    here("data", "raw", "days-gte"),
    pattern = glob2rx("*.nc"),
    full.names = TRUE)) |>
  mutate(fname = basename(path)) |>
  separate(fname, into = c("thresh", "var", "year", "ext"), sep = "[-.]") |>
  dplyr::select(-ext) |>
  # now group by thresh and var, and combine them
  group_by(thresh, var) |>
  summarise(
    group_path = concat_annual_gte(path, thresh[1], var[1])
  )
```

## Field averaging

Finally, let's do the field averaging (getting averages across each region) with `{exactextractr}`:

```{r}
#| label: 
```
